So, We have to design a Ml model which can detect the fraud Transaction( Here the transaction are home lone related Transaction) so we have data .csv of 20 columns 
That columns are:-
Transaction Type
Account number
Account type
class code
collatrael code
Short name
post_date
effective date
transaction code
actio code
Field number
field chgdesc
interest
principle
misc
description
operator_id
operator_name
batch_number
total
so in the data for each transaction we dont have some values for some transactions like field name, Field change
so we have derive features from this data. features like 
Transaction Amount:
Transaction Date and Time:
Transaction Frequency:
Account Age:
Historical Transaction Data:
Transaction Velocity:
Behavioral Biometrics
Account Balance
Geo-Velocity
write a python code to extract that features and store it in .csv file


import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Load your dataset
# Assuming your dataset is a CSV file with a column 'Class' for labels
# and the rest are features
data = pd.read_csv('fraud_dataset.csv')

# Preprocess the data
# Assuming the label column is named 'Class'
X = data.drop('Class', axis=1).values
y = data['Class'].values

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build the neural network model
model = Sequential([
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    Dense(32, activation='relu'),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy:.2f}")

# Predict on test set
y_pred = (model.predict(X_test) > 0.5).astype(int)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

















